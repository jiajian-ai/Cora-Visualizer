# Graphormer 与普通GNN方法原理与实现区别

## 1. 普通GNN简介
- 以GCN/GAT/GraphSAGE等为代表，通过聚合邻居信息更新节点嵌入，核心思想为“邻居聚合”。
- 各层通常只聚合一阶邻居，信息的多跳传播依赖堆叠多层网络。
- 对远距离结构和全局信息的表达能力有限。

## 2. Graphormer 结构化编码核心思路
- 基于 Transformer，每层皆可全局自注意力，但关键：通过结构编码（如最短路径SPD、节点中心性、边类型）让Transformer感知图结构！
- 除节点特征外，融入：
  - **SPD编码**：所有节点对最短路径距离的嵌入（解锁远程依赖能力）
  - **中心性嵌入**：节点度（degree）用作结构性信息注入
  - **边编码**：显式区分直连/多跳/无连边节点对关系
- 注意力和前馈都要结构偏置，学习到更强全局依赖与结构区分能力。

## 3. 代码结构主要特点（以 `graphormer_with_structural_encoding.py` 为例）
- 数据加载后，首先预计算全图的最短路径矩阵、各节点中心性。
- 多重嵌入层把结构特征和节点属性融合
- 每一层 GraphormerLayer 利用SPD、中心性、边编码以偏置形式强化自注意力计算，处理能力远超只邻居聚合的GNN。
- 输出结构与普通节点分类任务一致，训练方式等同标准GNN。

## 4. 适用场景对比
- **普通GNN擅长**：局部结构决定任务表现（如社交网络、局部社区）
- **Graphormer适合**：远距离节点相关性、本征图结构复杂（如分子、知识图谱、复杂通信图）

## 5. 相关可视化与分析
- 训练过程与参数曲线全保存在 `output/`，可通过不同方法结构对比直观了解模型表达力与全局交互能力。

---

[返回主导航](README.md)
